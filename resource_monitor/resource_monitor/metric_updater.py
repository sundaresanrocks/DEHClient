import pytz
import logging
from app import app
from datetime import datetime
import mongodb_wrapper
from runtime import runtime
import metric_handler
import threading
from timeloop import Timeloop
from datetime import timedelta
from lib.API_Wrapper import DEHAPIWrapper
from multiprocessing.pool import ThreadPool
import re

tl = Timeloop()
container_name = None
logger = logging.getLogger("./MetricsUpdater.log")

if app.config['secure_connection'].lower().strip() == "true":
    print("DEH Client - Attempting to establish communication with Docker Host over secured channel.")
    logger.info("DEH Client - Attempting to establish communication with Docker Host over secured channel.")
    CERT_BASE = app.config["tls_cert_path"]
    docker_ca_cert = CERT_BASE + "/ca.pem"
    docker_client_cert = CERT_BASE + "/cert.pem"
    docker_client_key = CERT_BASE + "/key.pem"
    https_url = app.config["docker_host"]
    measure_usage_client = metric_handler.MetricHandler(docker_ca_cert,
                                                        docker_client_cert,
                                                        docker_client_key, https_url, container_name)

elif app.config['secure_connection'].lower().strip() == "false":
    print("Warning DEH Client - Attempting to establish open communication with Docker Host i.e. unsecured. ")
    logger.info("Warning DEH Client - Attempting to establish open communication with Docker Host i.e. unsecured. ")
    docker_ca_cert = None
    docker_client_cert = None
    docker_client_key = None
    https_url = app.config["docker_host"]
    http_url = re.sub("^https://", "http://", https_url)
    measure_usage_client = metric_handler.MetricHandler(docker_ca_cert,
                                                        docker_client_cert,
                                                        docker_client_key, http_url, container_name)


class MetricsUpdater:
    __logger = logging.getLogger("DEHClientEnabler.metric_updater")
    MAX_THREAD_POOL_SIZE = 50

    def __init__(self):
        """Initializes the logger and the docker client connection.
        """
        # self.CERT_BASE = app.config["tls_cert_path"]
        # self.docker_ca_cert = self.CERT_BASE + "/ca.pem"
        # self.docker_client_cert = self.CERT_BASE + "/cert.pem"
        # self.docker_client_key = self.CERT_BASE + "/key.pem"
        # self.https_url = app.config["docker_host"]
        # self.container_name = None
        # self.DOCKER_CLIENT_TIMEOUT = 3
        # self.keep_measuring = True

        self.__logger = logging.getLogger("./MetricsUpdater.log")

        self.mongo_client = mongodb_wrapper.MongoAPI(hostname=app.config["mongo_host"],
                                                     port=app.config["mongo_port"],
                                                     database=app.config["mongo_db"],
                                                     collection=app.config["mongo_collection_metrics"])

        # Internal config
        self.metrics_capture_time_interval = runtime.config["unit_of_measure"]
        self.metrics_sorting_by = runtime.config["sort_by"]
        self.metrics_no_of_records = runtime.config["no_of_records_per_timestamp"]

        # self.measure_usage_client = metric_handler.MetricHandler(self.docker_ca_cert, self.docker_client_cert,
        #                                                          self.docker_client_key,
        #                                                          self.https_url,
        #                                                          self.container_name)

        # thread pool
    def thread_start(self):
        self.__thread = threading.Thread(target=self.run, args=())
        self.__thread.daemon = True
        self.__thread.start()
        self.__thread.join()

    def manage_write_metrics_to_db(self, individual_metric):
        """
        Format the metrics generated by metrics_handler to the desired DataModel recommended by RRM & publish the data
        Implemented : Updates the DB
        Future : POST to RRM Consumer API
        """
        utc_current_datetime = datetime.now(pytz.timezone("UTC"))
        # utc_current_datetime_str = utc_current_datetime.strftime("%Y-%m-%d %H:%M:%S %Z%z")
        utc_current_datetime_str = utc_current_datetime.strftime("%Y-%m-%dT%H:%M:%SZ")
        try:
            for i in individual_metric:
                resource_id = individual_metric[i]["info"]["container_id"]
                current_cpu_percent = individual_metric[i]["Volume"]["cpu"]["cpu_percent"]
                current_mem_percent = individual_metric[i]["Volume"]["mem"]["mem_percent"]
                uptime = individual_metric[i]["Uptime"]
                hostname = individual_metric[i]["HostName"]
                resource_name = individual_metric[i]["ResourceID"]
                ip = individual_metric[i]["IP"]
                bse_id = individual_metric[i]["BSE_ID"]
                uid = individual_metric[i]["RRM_ID"]
                image = individual_metric[i]["Image"]
                updated_cpu_present = {"time_stamp": utc_current_datetime_str,
                                       "cpu_percent": current_cpu_percent}
                updated_mem_present = {"time_stamp": utc_current_datetime_str,
                                       "mem_percent": current_mem_percent}
                # Read DB if the resource data is already persisted. If exists update record
                documents = self.mongo_client.read({"_id": resource_id})
                if documents:
                    formatted_data = {}
                    for document in documents:
                        cpu_percent = self.metrics_sorting_by["cpu"]
                        mem_percent = self.metrics_sorting_by["memory"]
                        cpu_update = self.mongo_client.update_array(resource_id, "cpu_percent", updated_cpu_present,
                                                                    cpu_percent,
                                                                    retain_no_of_records=self.metrics_no_of_records)
                        mem_update = self.mongo_client.update_array(resource_id, "mem_percent", updated_mem_present,
                                                                    mem_percent,
                                                                    retain_no_of_records=self.metrics_no_of_records)
                        # If rrm_id & bse_id generated after record persisted in mongodb, update the same.
                        mongo_bse_id = document["BSE_ID"]
                        mongo_uid = document["RRM_ID"]
                        if mongo_uid is None:
                            uid = individual_metric[i]["RRM_ID"]
                        if mongo_bse_id is None:
                            bse_id = individual_metric[i]["BSE_ID"]

                        self.mongo_client.update_one(resource_id, {"uptime": uptime,
                                                                   "RRM_ID": uid,
                                                                   "BSE_ID": bse_id})

                # If new resource create a new record/ document
                else:
                    """
                    # GET BSE registration info
                    # TODO handle multiple BSE registrations with same name
                    #  & attempt to update IDs only if previous iterations failed to get info
                    host = app.config["DEH_BSE_Proxy_URL"]
                    method = app.config["DEH_BSE_GET_SERVICE"]
                    # Note : The service name is case sensitive
                    deh_bse_obj = DEHAPIWrapper(host, method,
                                                payload={"service_name": resource_name})
                    status_code, response = deh_bse_obj.deh_bse_get_running_services()
                    if status_code == 200 and response.json() != {}:
                        for bse_response_dict in response.json():
                            bse_id = response.json()[bse_response_dict]["ID"]
                            # Exit in case of multiple registration with same name
                            break
                    else:
                        bse_id = None
                    # GET RRM registration info
                    method = app.config["DEHEnablerHub_Search_Resource"]
                    deh_enabler_hub_obj = DEHAPIWrapper()
                    parameters = {"name": resource_name}
                    status_code, response = deh_enabler_hub_obj.deh_enabler_hub_resource_search(payload=parameters,
                                                                                                method=method)
                    if status_code == 200:
                        contents = response.json()["content"]
                        if len(contents) > 0:
                            for content in contents:
                                rrm_id = content["uid"]
                    """
                    # Writing to DB

                    formatted_data = {"_id": resource_id,
                                      "uptime": uptime,
                                      "hostname": hostname,
                                      "ip": ip,
                                      "image": image,
                                      "BSE_ID": bse_id,
                                      "RRM_ID": uid,
                                      "lastupdated": utc_current_datetime_str,
                                      "cpu_percent": [updated_cpu_present],
                                      "mem_percent": [updated_mem_present]}

                    # TODO: Retain Historic Data in DB
                    if not runtime.config['db_keep_non_uid_records']:
                        if formatted_data['RRM_ID'] is not None:
                            write = self.mongo_client.write(formatted_data)
                            if write:
                                MetricsUpdater.__logger.info("Metrics data for container id : {} "
                                                             "updated successfully to local DB.".format(resource_id))
                            else:
                                MetricsUpdater.__logger.error("Failed to write Metrics data for container id : {} "
                                                              "to local DB.".format(resource_id))
                        else:
                            MetricsUpdater.__logger.warning("Skipping persisting metrics data to DB since the "
                                                            "container id : {} of DEH Resource : {} , "
                                                            "is not associated with uid."
                                                            .format(formatted_data['_id'],
                                                                    formatted_data['image']))
                    elif runtime.config['db_keep_non_uid_records']:
                        write = self.mongo_client.write(formatted_data)
                        if write:
                            MetricsUpdater.__logger.info("Metrics data for container id : {} "
                                                         "updated successfully to local DB.".format(resource_id))
                        else:
                            MetricsUpdater.__logger.warning("Skipping persisting metrics data to DB since the "
                                                            "container id : {} of DEH Resource : {} , "
                                                            "is not associated with uid."
                                                            .format(formatted_data['_id'],
                                                                    formatted_data['image']))

        except KeyError as error:
            MetricsUpdater.__logger.error("Exception encountered, while monitoring container id {} possible causes:"
                                          "Cause 1: Container under monitoring stopped while metrics generation "
                                          "was in progress. or . "
                                          "Cause 2: Metrics not generated properly ie certain fields not captured. "
                                          "Please check and start/ restart containers".format(resource_id))
            MetricsUpdater.__logger.error("Exception encountered : KeyError & Possibly missing keyword. "
                                          "details : {}. ".format(error))

        except Exception as error:
            MetricsUpdater.__logger.error("Exception encounter while monitoring container {}. ".format(resource_id))
            MetricsUpdater.__logger.error("Exception details : {}. ".format(error))

    @tl.job(interval=timedelta(seconds=runtime.config['unit_of_measure']))
    def measure_usage(resource_status="Running"):
        max_usage = 0
        try:
            metrics = measure_usage_client.get_metrics({"status": resource_status})
            if metrics:
                for individual_metric in metrics:
                    # try:
                    # This loop is for accessing the values of dict individual_metric
                    utc_current_datetime = datetime.now(pytz.timezone("UTC"))
                    utc_current_datetime_str = utc_current_datetime.strftime("%Y-%m-%d %H:%M:%S %Z%z")
                    metrics_updater = MetricsUpdater()
                    metrics_updater.manage_write_metrics_to_db(individual_metric)
                    # except KeyError as error:
                    #     MetricsUpdater.__logger.error(
                    #         "Exception encountered while writing data to local DB for docker container : "
                    #         "{} ".format(individual_metric))
                    #     MetricsUpdater.__logger.error("Exception encountered : KeyError & Possibly missing keyword. "
                    #                                   "details : {}. ".format(error))
                    #
                    # except Exception as error:
                    #     MetricsUpdater.__logger.error(
                    #         "Exception encountered while writing metrics data to local DB for docker container : "
                    #         "{}. ".format(individual_metric))
                    #     MetricsUpdater.__logger.error("Exception details : {}. ".format(error))

            else:
                MetricsUpdater.__logger.warning("No Docker Container/s is/are running on this Docker Host "
                                                "for monitoring, continuing to monitoring. "
                                                "To generate and start tracking metrics, "
                                                "Please start some Container/s instances of DEH resources with "
                                                "valid RRM registration(uid).")
        except KeyError as error:
            MetricsUpdater.__logger.error("Exception encountered while writing metrics data to local db, "
                                          "KeyError & Possibly missing keyword. "
                                          "details : {}. ".format(error))

        except Exception as error:
            MetricsUpdater.__logger.error("Exception encountered while writing metrics data to local db, "
                                          "details : {}. ".format(error))

    @tl.job(interval=timedelta(seconds=runtime.config['timestamp']))
    def post_metrics_rrm_thread(resource_status="Running"):
        # # Read data from metrics db
        mongo_client = mongodb_wrapper.MongoAPI(hostname=app.config["mongo_host"],
                                                port=app.config["mongo_port"],
                                                database=app.config["mongo_db"],
                                                collection=app.config["mongo_collection_metrics"])
        documents = mongo_client.find_projection({},
                                                 {"cpu_percent":
                                                      {"$slice": runtime.config["no_of_records_per_timestamp"]},
                                                  "mem_percent":
                                                      {"$slice": runtime.config["no_of_records_per_timestamp"]}}
                                                 )
        records = []
        for document in documents:
            records.append([document])
        deh_enabler_hub_obj = DEHAPIWrapper()
        try:
            with ThreadPool(min(MetricsUpdater.MAX_THREAD_POOL_SIZE, len(records))) as pool:
                post_metrics = pool.map(deh_enabler_hub_obj.initiate_post_deh_metrics_request, records)
            return
        except Exception as E:
            # MetricsUpdater.__logger.error("Exception Encountered : {} ".format(E))
            pass

    def run(self):
        try:
            tl.start(block=True)
        except Exception as E:
            # MetricsUpdater.__logger.error("Exception Encountered : {} ".format(E))
            pass


if __name__ == "__main__":
    metrics_updater = MetricsUpdater()
    metrics_updater.run()
    """
    with ThreadPoolExecutor() as executor:
        monitor = MetricsMonitor()
        mem_thread = executor.submit(monitor.measure_usage(resource))
        try:
            fn_thread = executor.submit(my_analysis_function)
            result = fn_thread.result()
        finally:
            monitor.keep_measuring = False
            max_usage = mem_thread.result()
    
        print(f"Peak memory usage: {max_usage}")
        """
